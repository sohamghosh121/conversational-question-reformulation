{
    "dataset_reader": {
        "type": "quac_custom",
        "lazy": true,
        "num_context_answers": 2,
        "token_indexers": {
            "elmo": {
                "type": "elmo_characters"
            },
            "token_characters": {
                "type": "characters",
                "character_tokenizer": {
                    "byte_encoding": "utf-8",
                    "end_tokens": [
                        260
                    ],
                    "start_tokens": [
                        259
                    ]
                }
            }
        }
    },
    "iterator": {
        "type": "bucket",
        "batch_size": 3,
        "max_instances_in_memory": 100,
        "sorting_keys": [
            [
                "question",
                "num_fields"
            ],
            [
                "passage",
                "num_tokens"
            ]
        ]
    },
    "model": {
        "type": "dialog_qa_ctx",
        "dropout": 0.2,
        "initializer": [],
        "marker_embedding_dim": 10,
        "num_context_answers": 2,
        "ctx_q_encoder": {
            "type": "biatt_ctx_multi",
              "coref_layer": {
                "type": "gru",
                "bidirectional": true,
                "hidden_size": 100,
                "input_size": 1124,
                "num_layers": 1
            },
            "qa_attention": {
                "type": "linear",
                "combination": "x,y,x*y",
                "tensor_1_dim": 200,
                "tensor_2_dim": 200
            },
            "qq_attention": {
                "type": "linear",
                "combination": "x,y,x*y",
                "tensor_1_dim": 200,
                "tensor_2_dim": 200
            },
            "combination": "entropy+exponential",
            "num_turns": 3,
            "use_antecedent_score": true,
            "use_mention_score": true
        },
        "phrase_layer": {
            "type": "gru",
            "bidirectional": true,
            "hidden_size": 100,
            "input_size": 1134,
            "num_layers": 1
        },
        "residual_encoder": {
            "type": "gru",
            "bidirectional": true,
            "hidden_size": 100,
            "input_size": 200,
            "num_layers": 1
        },
        "span_end_encoder": {
            "type": "gru",
            "bidirectional": true,
            "hidden_size": 100,
            "input_size": 400,
            "num_layers": 1
        },
        "span_start_encoder": {
            "type": "gru",
            "bidirectional": true,
            "hidden_size": 100,
            "input_size": 200,
            "num_layers": 1
        },
        "text_field_embedder": {
            "elmo": {
                "type": "elmo_token_embedder",
                "do_layer_norm": false,
                "dropout": 0.2,
                "options_file": "https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json",
                "weight_file": "https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5"
            },
            "token_characters": {
                "type": "character_encoding",
                "dropout": 0.2,
                "embedding": {
                    "embedding_dim": 20,
                    "num_embeddings": 262
                },
                "encoder": {
                    "type": "cnn",
                    "embedding_dim": 20,
                    "ngram_filter_sizes": [
                        5
                    ],
                    "num_filters": 100
                }
            }
        }
    },
    "train_data_path": "data/val-small.json",
    "validation_data_path": "data/val-small.json",
    "trainer": {
        "cuda_device": -1,
        "learning_rate_scheduler": {
            "type": "reduce_on_plateau",
            "factor": 0.5,
            "mode": "max",
            "patience": 10
        },
        "num_epochs": 30,
        "optimizer": {
            "type": "adam",
            "lr": 0.0001
        },
        "patience": 20,
        "validation_metric": "+f1"
    },
    "validation_iterator": {
        "type": "bucket",
        "batch_size": 3,
        "max_instances_in_memory": 100,
        "sorting_keys": [
            [
                "question",
                "num_fields"
            ],
            [
                "passage",
                "num_tokens"
            ]
        ]
    }
}
